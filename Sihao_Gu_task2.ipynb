{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(readGz(\"assignment1/train.json.gz\"))\n",
    "train_data = data[:100000]\n",
    "valid_data = data[100000:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(alpha,beta_u,beta_i,m,n,gamma_u,gamma_i,user_dict,item_dict):\n",
    "    rating = alpha  + (beta_u[m] if m in beta_u else 0)  + (beta_i[n] if n in beta_i else 0)\n",
    "    if m in user_dict and n in item_dict:\n",
    "        rating +=np.inner(gamma_u[user_dict[m]],gamma_i[item_dict[n]]) \n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial alpha beta_i beta_u  gamma_u gamma_i\n",
    "#Method to Train The Latent Factor Model. \n",
    "def latentfactor(lam,data,k,times):\n",
    "    users = defaultdict(lambda: defaultdict(int))\n",
    "    items = defaultdict(lambda: defaultdict(int))\n",
    "    beta_u = defaultdict(float)\n",
    "    beta_i = defaultdict(float)\n",
    "    user_dict = defaultdict(int)\n",
    "    user_num=0\n",
    "    item_dict = defaultdict(int)\n",
    "    item_num=0\n",
    "    for i in data:\n",
    "        user, item, rating = i['reviewerID'], i['itemID'], i['rating']\n",
    "        users[user][item] = rating\n",
    "        items[item][user] = rating\n",
    "        if user not in user_dict:\n",
    "            user_dict[user]=user_num\n",
    "            user_num+=1\n",
    "        if item not in item_dict:\n",
    "            item_dict[item]=item_num\n",
    "            item_num+=1\n",
    "    \n",
    "# generating gamma_u,gamma_i\n",
    "    gamma_u=np.random.normal(scale=1./k,size=(len(users),k))\n",
    "    gamma_i=np.random.normal(scale=1./k,size=(len(items),k ))\n",
    "\n",
    "    #update alpha beta_u beta_i gamma_u gamma_i\n",
    "    alpha=0\n",
    "    for time in range(times):\n",
    "        alpha=0\n",
    "        for i in users:\n",
    "            for j in users[i]:\n",
    "                alpha += users[i][j] - beta_u[i] -beta_i[j] - np.inner(gamma_u[user_dict[i]],gamma_i[item_dict[j]])\n",
    "        alpha /= len(data)\n",
    "        \n",
    "        for i in users:\n",
    "            beta_u[i] = 0\n",
    "            for j in users[i]:\n",
    "                beta_u[i] += users[i][j]  - alpha - beta_i[j] - np.inner(gamma_u[user_dict[i]],gamma_i[item_dict[j]])\n",
    "            beta_u[i] /= (lam + len(users[i])) \n",
    "            \n",
    "        for j in items:\n",
    "            beta_i[j] = 0\n",
    "            for i in items[j]:\n",
    "                beta_i[j] += items[j][i]  -alpha - beta_u[i] - np.inner(gamma_u[user_dict[i]],gamma_i[item_dict[j]])\n",
    "            beta_i[j] /= (lam + len(items[j]))\n",
    "    \n",
    "        for i in users:\n",
    "            for d in range(k):\n",
    "                gamma_u[user_dict[i]][d] = 0\n",
    "                for j in users[i]:\n",
    "                    gamma_u[user_dict[i]][d] += gamma_i[item_dict[j]][d]*(users[i][j]  - alpha - beta_i[j]  +gamma_i[item_dict[j]][d]*gamma_i[item_dict[j]][d]-np.inner(gamma_u[user_dict[i]],gamma_i[item_dict[j]]) )\n",
    "                    gamma_u[user_dict[i]][d]  /= (lam + gamma_i[item_dict[j]][d]*gamma_i[item_dict[j]][d])\n",
    "                    \n",
    "        for j in items:\n",
    "            for d in range(k):\n",
    "                gamma_i[item_dict[j]][d] = 0\n",
    "                for i in items[j]:\n",
    "                    gamma_i[item_dict[j]][d] += gamma_u[user_dict[i]][d]*(users[i][j]  - alpha - beta_u[i] - np.inner(gamma_u[user_dict[i]],gamma_i[item_dict[j]]) +gamma_u[user_dict[i]][d]*gamma_u[user_dict[i]][d] )\n",
    "                    gamma_i[item_dict[j]][d] /= (lam + gamma_u[user_dict[i]][d]*gamma_u[user_dict[i]][d])\n",
    "    return alpha,beta_u,beta_i,user_dict,item_dict,gamma_i,gamma_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha,beta_u,beta_i,user_dict,item_dict,gamma_i,gamma_u=latentfactor(6.4,data,9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output prediction file\n",
    "\n",
    "predictions = open(\"assignment1/predictions_Rating.csv\", 'w')\n",
    "for l in open(\"assignment1/pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)  \n",
    "        continue\n",
    "    u,i = l.strip().split('-')   \n",
    "    rating=predict(alpha,beta_u,beta_i,u,i,gamma_u,gamma_i,user_dict,item_dict)\n",
    "    predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
